{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINGPT_PATH = 'C:\\\\Users\\\\KAHWLEE\\\\Desktop\\\\genai\\\\minGPT'\n",
    "DATA_SRC_PATH = 'C:\\\\Users\\\\KAHWLEE\\\\Desktop\\\\genai\\\\minGPT_history_books\\\\data_source'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, MINGPT_PATH)\n",
    "sys.path.insert(0, DATA_SRC_PATH)\n",
    "\n",
    "import re\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "from mingpt.utils import set_seed, setup_logging, CfgNode as CN\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def open_n_preprocess_text(path):\n",
    "    input_text = open(path, encoding=\"utf8\").read()\n",
    "    # Remove substrings with numbers between spaces\n",
    "    processed_text = re.sub(r'\\s\\d+\\s', '\\n', input_text)\n",
    "\n",
    "    # Reduce consecutive newlines to a maximum of two\n",
    "    processed_text = re.sub(r'\\n{3,}', '\\n\\n', processed_text)\n",
    "\n",
    "    # Remove leading and trailing whitespaces\n",
    "    processed_text = processed_text.strip()\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def count_words(input_string):\n",
    "    words = input_string.split()\n",
    "    print(f\"number of words: {len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        C.block_size = 128\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config.block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.config.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.config.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        # return as tensors\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words: 53270\n",
      "number of words: 117283\n",
      "number of words: 33401\n",
      "number of words: 128890\n",
      "number of words: 75539\n",
      "number of words: 49475\n",
      "number of words: 79785\n",
      "number of words: 4628\n",
      "number of words: 18976\n",
      "number of words: 60574\n",
      "number of words: 621821\n"
     ]
    }
   ],
   "source": [
    "# List all files in the directory\n",
    "files = os.listdir(DATA_SRC_PATH)\n",
    "files_read = []\n",
    "for file_name in files:\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(DATA_SRC_PATH, file_name)\n",
    "        text1 = open_n_preprocess_text(file_path)\n",
    "        count_words(text1)\n",
    "        files_read.append(text1)\n",
    "data = '\\n\\n '.join(files_read)\n",
    "count_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "\n",
    "    C = CN()\n",
    "\n",
    "    # system\n",
    "    C.system = CN()\n",
    "    C.system.seed = 3407\n",
    "    C.system.work_dir = './out/chargpt'\n",
    "\n",
    "    # data\n",
    "    C.data = CharDataset.get_default_config()\n",
    "\n",
    "    # model\n",
    "    C.model = GPT.get_default_config()\n",
    "    C.model.model_type = 'gpt-mini'\n",
    "\n",
    "    # trainer\n",
    "    C.trainer = Trainer.get_default_config()\n",
    "    C.trainer.learning_rate = 4e-4 # the model we're using is so small that we can go a bit faster\n",
    "    C.trainer.num_workers = 0 # error when in localhost\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        C.block_size = 128\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config.block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.config.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.config.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        # return as tensors\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:\n",
      "    seed: 3407\n",
      "    work_dir: ./out/chargpt\n",
      "data:\n",
      "    block_size: 128\n",
      "model:\n",
      "    model_type: gpt-mini\n",
      "    n_layer: None\n",
      "    n_head: None\n",
      "    n_embd: None\n",
      "    vocab_size: None\n",
      "    block_size: None\n",
      "    embd_pdrop: 0.1\n",
      "    resid_pdrop: 0.1\n",
      "    attn_pdrop: 0.1\n",
      "trainer:\n",
      "    device: auto\n",
      "    num_workers: 0\n",
      "    max_iters: None\n",
      "    batch_size: 64\n",
      "    learning_rate: 0.0004\n",
      "    betas: (0.9, 0.95)\n",
      "    weight_decay: 0.1\n",
      "    grad_norm_clip: 1.0\n",
      "\n",
      "data has 4548434 characters, 115 unique.\n"
     ]
    }
   ],
   "source": [
    "# get default config and overrides from the command line, if any\n",
    "config = get_config()\n",
    "print(config)\n",
    "setup_logging(config)\n",
    "set_seed(config.system.seed)\n",
    "\n",
    "# construct the training dataset\n",
    "train_dataset = CharDataset(config.data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.72M\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "config.model.vocab_size = train_dataset.get_vocab_size()\n",
    "config.model.block_size = train_dataset.get_block_size()\n",
    "model = GPT(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"C:\\\\Users\\\\KAHWLEE\\\\Desktop\\\\genai\\\\minGPT_history_books\\\\out\\\\chargpt\\\\model.pt\"  # Provide the correct path to your saved model\n",
    "state_dict = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config.trainer, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(115, 192)\n",
       "    (wpe): Embedding(128, 192)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (c_proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (act): NewGELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=192, out_features=115, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_prompt(context = \"kerajaan melaka\"):\n",
    "    print(\"generating ...\")\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
    "        y = model.generate(x, 500, temperature=1.0, do_sample=True, top_k=10)[0]\n",
    "        completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "        print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ...\n",
      "kerajaan johorh dkekOakOaéLe ae Oa areagO 0ak a Okaa VaO k0 daaa Vg0khOé0hn eb ann0 r0e  Ianah dnr♦O a OOaOOI a 0 OaOa kOuee aLOe 0 VV aO ahnOn kea  kV neagL IaV kOana  aG’eegekre Oanraag V n  00IaaGagraG0 egOga d Ike Ir0Onean0  eVr   a OgagaV0aeganOO dI0VgLaakake nVO a 0IVrO  kaOVnrVr a nanr V ann0ga eaGV0rn IOna 0aa   deag0rr e eg Vg0anegILngLaOaea kOgaa nOaGahaeeahOa e Va ereVnOVran eenb0nn IVOkaera  ah kan d Ia ah VkOaaan0 aOeaer0ak krVanakr0 kag0 0aGea anearOnaeg0Vna O OVg Oa nVgrOnnrV OaG kVkanaka a  k \n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpt_prompt(context = \"kerajaan johor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
