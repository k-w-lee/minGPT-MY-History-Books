{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINGPT_PATH = 'genai\\\\minGPT'\n",
    "DATA_SRC_PATH = 'genai\\\\minGPT_history_books\\\\data_source'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, MINGPT_PATH)\n",
    "sys.path.insert(0, DATA_SRC_PATH)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd # \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "from mingpt.utils import set_seed, setup_logging, CfgNode as CN\n",
    "import re\n",
    "import os\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_n_preprocess_text(path):\n",
    "    input_text = open(path, encoding=\"utf8\").read()\n",
    "    # Remove substrings with numbers between spaces\n",
    "    processed_text = re.sub(r'\\s\\d+\\s', '\\n', input_text)\n",
    "\n",
    "    # Reduce consecutive newlines to a maximum of two\n",
    "    processed_text = re.sub(r'\\n{3,}', '\\n\\n', processed_text)\n",
    "\n",
    "    # Remove leading and trailing whitespaces\n",
    "    processed_text = processed_text.strip()\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def count_words(input_string):\n",
    "    words = input_string.split()\n",
    "    print(f\"number of words: {len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words: 53270\n",
      "number of words: 117283\n",
      "number of words: 33401\n",
      "number of words: 128890\n",
      "number of words: 75539\n",
      "number of words: 49475\n",
      "number of words: 79785\n",
      "number of words: 4628\n",
      "number of words: 18976\n",
      "number of words: 60574\n",
      "number of words: 621821\n"
     ]
    }
   ],
   "source": [
    "# List all files in the directory\n",
    "files = os.listdir(DATA_SRC_PATH)\n",
    "files_read = []\n",
    "for file_name in files:\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(DATA_SRC_PATH, file_name)\n",
    "        text1 = open_n_preprocess_text(file_path)\n",
    "        count_words(text1)\n",
    "        files_read.append(text1)\n",
    "data = '\\n\\n '.join(files_read)\n",
    "count_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "\n",
    "    C = CN()\n",
    "\n",
    "    # system\n",
    "    C.system = CN()\n",
    "    C.system.seed = 3407\n",
    "    C.system.work_dir = './out/chargpt'\n",
    "\n",
    "    # data\n",
    "    C.data = CharDataset.get_default_config()\n",
    "\n",
    "    # model\n",
    "    C.model = GPT.get_default_config()\n",
    "    C.model.model_type = 'gpt-mini'\n",
    "\n",
    "    # trainer\n",
    "    C.trainer = Trainer.get_default_config()\n",
    "    C.trainer.learning_rate = 4e-4 # the model we're using is so small that we can go a bit faster\n",
    "    C.trainer.num_workers = 0 # error when in localhost\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        C.block_size = 128\n",
    "        return C\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        self.config = config\n",
    "\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config.block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.config.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.config.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        # return as tensors\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:\n",
      "    seed: 3407\n",
      "    work_dir: ./out/chargpt\n",
      "data:\n",
      "    block_size: 128\n",
      "model:\n",
      "    model_type: gpt-mini\n",
      "    n_layer: None\n",
      "    n_head: None\n",
      "    n_embd: None\n",
      "    vocab_size: None\n",
      "    block_size: None\n",
      "    embd_pdrop: 0.1\n",
      "    resid_pdrop: 0.1\n",
      "    attn_pdrop: 0.1\n",
      "trainer:\n",
      "    device: auto\n",
      "    num_workers: 0\n",
      "    max_iters: None\n",
      "    batch_size: 64\n",
      "    learning_rate: 0.0004\n",
      "    betas: (0.9, 0.95)\n",
      "    weight_decay: 0.1\n",
      "    grad_norm_clip: 1.0\n",
      "\n",
      "data has 4548434 characters, 115 unique.\n"
     ]
    }
   ],
   "source": [
    "# get default config and overrides from the command line, if any\n",
    "config = get_config()\n",
    "print(config)\n",
    "setup_logging(config)\n",
    "set_seed(config.system.seed)\n",
    "\n",
    "# construct the training dataset\n",
    "train_dataset = CharDataset(config.data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.72M\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "config.model.vocab_size = train_dataset.get_vocab_size()\n",
    "config.model.block_size = train_dataset.get_block_size()\n",
    "model = GPT(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "# construct the trainer object\n",
    "trainer = Trainer(config.trainer, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration callback\n",
    "def batch_end_callback(trainer):\n",
    "\n",
    "    if trainer.iter_num % 10 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "\n",
    "    if trainer.iter_num % 500 == 0:\n",
    "        # evaluate both the train and test score\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # sample from the model...\n",
    "            context = \"Apakah Sejarah malaysia?\"\n",
    "            x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
    "            y = model.generate(x, 500, temperature=1.0, do_sample=True, top_k=10)[0]\n",
    "            completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "            print(completion)\n",
    "        # save the latest model\n",
    "        print(\"saving model\")\n",
    "        ckpt_path = os.path.join(config.system.work_dir, \"model.pt\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        # revert model to training mode\n",
    "        model.train()\n",
    "\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "# run the optimization\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
